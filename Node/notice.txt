q1: duplicate key
      现有id为唯一键，正常情况下判断id为1的记录是否存在，如果不存在则加入id为1的记录。
      但现在有两个同时的请求都在查找id为1的记录，并都判断为不存在，就同时插入id为1的记录，这时会发生duplicate key错误。
  a1: 使用文件锁
        在插入数据前创建与本次请求参数一致的文件，在插入完成后删除该文件。目的是以判断文件是否存在来确定插入是否完成，
        如果文件存在则跳过插入。另外，为防止本应插入成功的记录，由于某种原因失败，使得文件锁变为死锁，还应该判断文件
        的存在时间，如果存在时间过长，则删掉该文件锁。
        
q2: duplicate key
      PostgreSQL并发删除插入同一条记录时出现duplicate key报错。
  a1: http://blog.chinaunix.net/uid-20726500-id-5289907.html
        
q3: file_put_contents file_get_content 并发
      先发送请求用file_put_contents写入文件，立刻发送新请求使用file_get_content获取文件内容，是不能够获取文件内容的，即使file_put_contents
      已经正常返回
  a1: php回收机制可能还没有正常结束，资源没有释放，file_get_content无法获取文件内容。
  
  
q4: 发现重复请求，如何解决。
   
   a1:使用分布式redis锁但是有坑 https://blog.huoding.com/2015/09/14/463
   a2:http 100-continue https://www.cnblogs.com/yibuyisheng/p/5649251.html https://www.cnblogs.com/wmShareBlog/p/5924144.html
  
  
redis  cluster
php 加速器 apc xdebug lume-sweag unittest
apche mod_mem_cache 
jira
bitbucket
grafana
sonar qube
